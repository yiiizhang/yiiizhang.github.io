<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Yi Zhang</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/small-business.css" rel="stylesheet">
  <link rel="stylesheet" href="css/all.css" />
  <link rel="stylesheet" href="css/academicons.css" />
  <style type="text/css">
    .content {
      margin-top: 0;
      margin-bottom: 0
    }
  </style>
  <meta http-equiv="Content-Type" content="text/html; charset=gbk">
  <meta name="google-site-verification" content="qEih9m0y-6X0QuisQYfHSxOvkW-o5Q3dfxuQ5Z4JtGA" />

</head>

<body>

  <!-- Page Content -->
  <div class="container">

    <!-- Heading Row -->
    <div class="row my-4">
      <div class="col-lg-4">
        <img class="img-fluid rounded img-responsive" style="width:100%" src="img/me_small.png" alt="">
      </div>
      <!-- /.col-lg-8 -->
      <div class="col-lg-7">
        <h1>Yi Zhang&nbsp;<small>(å¼ ç¿¼)</small></h1>        
        <p>Email: yi [dot] zhang [at] bjtu [dot] edu [dot] cn </p>

           <p>Yi Zhang is a postdoctoral researcher at Huawei Co., Ltd, China, advised by Dr. Baoxing Huai. </p>
<!--         Starting from August 2023, she will become an assistant professor in the Computer Science Department at USC.  -->
       <p> Yi received his Ph.D. from <span style="color:#4169E1"><a
              href="http://www.bjtu.edu.cn/">School of Computer and Information Technology, BJTU</a></span>, where he was advised by <a href="https://dblp.uni-trier.de/pid/84/286.html">Prof. Jitao Sang</a>. </p>

        <p> Yi serves as a reviewer for several top-tier academic conferences, including ICLR, CVPR, IJCAI, ACM MM and KDD. </p>
                <p>His CV is available <a href="https://yiiizhang.github.io/files/cv.pdf" target="_blank">here</a>.</p>

<!--         <p class=" m-0">I am a Ph.D candidate in the <span style="color:#4169E1"><a -->
<!--               href="http://scit.bjtu.edu.cn/">School of Computer and Information Technology, BJTU</a></span>. </p> -->
<!--           <p>I work with <span style="color:#4169E1"><a href="http://faculty.bjtu.edu.cn/9129/">Prof. Jitao Sang</a></span> focusing on problems in -->
<!--           <strong> Multi-modal Machine learning</strong>. </p> -->
<!--             <p>Currently, I am working -->
<!--           on debiasing in modern machine learning systems.</p> -->
        <p></p>
        <!-- <p>Before joining UCLA, I spent one year in <span style="color:#4169E1"><a
              href="https://engineering.virginia.edu/departments/computer-science">Department of Computer Science,
              University of Virginia</a></span>. Had a great experience in Charlottesville! </p> -->

        
        <!-- <a class="btn btn-primary btn-lg" href="#">Call to Action!</a> -->
        <p></p>
      </div>
      <!-- /.col-md-4 -->
    </div>
    <!-- /.row -->

<!--     <div class=" my-4 text-left" >
            <h2>Research</h2>
            <p >
I am broadly interested in research about how to get machines to understand and respond to human languages (natural language processing & machine learning). A few questions that drive my recent research are:

how can we get models to efficiently learn knowledge?
how can we reduce potential harms learned by the model?
how can we advance better models and humans collaborations?Before joining UCLA, I spent one year in <span style="color:#4169E1"><a href="https://engineering.virginia.edu/departments/computer-science">Department of Computer Science, University of Virginia</a></span>. Had a great experience in Charlottesville! </p>
          <p></p>
      </div> -->

    <div class=" my-4 text-left">
      <h2>Recent News</h2>

      <p> * [07.2024] Our paper <span style="color:#4169E1"><a href="https://dl.acm.org/doi/10.1145/3664647.3681524">Poisoning for Debiasing: Fair Recognition via Eliminating Bias Uncovered in Data Poisoning
      </a></span> has been accepted by ACM MM 2024.</p>
      
      <p> * [08.2023] I joined Huawei Co., Ltd as a postdoctoral researcher.</p> 
      
      <p> * [07.2023] Our paper <span style="color:#4169E1"><a href="">Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features
      </a></span> has been accepted by ACM MM 2023.</p>

      <p> * [06.2023] I am proud to announce that I have successfully passed my Doctoral Thesis Defense and have received Ph.D. from Beijing Jiaotong University.</p>
      
      <p> * [04.2023] Our paper <span style="color:#4169E1"><a href="https://arxiv.org/abs/2304.13273">From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping
      </a></span> has been accepted by IJCAI 2023.</p>
      
      <p> * [06.2022] Our paper <span style="color:#4169E1"><a href="">Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models
      </a></span> has been accepted by ACM MM 2022.</p>
      
      <p> * [10.2021] I gave a tutorial on <span style="color:#4169E1"><a href="https://2021.acmmm.org/tutorials">Trustworthy Multimedia Analysis</a></span> in ACM MM 2021.</p>
      
      <p> * [07.2020] Our paper <span style="color:#4169E1"><a href="">Towards Accuracy-Fairness Paradox: Adversarial Example-based Data Augmentation for Visual Debiasing
      </a></span> has been accepted by ACM MM 2020.</p>
        <!-- <p> * [07.2019] Our paper <span style="color:#4169E1"><a href="https://arxiv.org/abs/1811.08489">Balanced
              Datasets
              Are Not Enough</a></span> has been accepted by ICCV 2019.</p>
        <p> * [05.2019] Our paper <span style="color:#4169E1"><a href="https://arxiv.org/abs/1906.08976">Mitigating
              Gender
              Bias in Natural Language Processing: Literature Review </a></span> has been accepted by ACL 2019.</p>
        <p> * [05.2019] Our paper  <span style="color:#4169E1"><a href=""> Analyzing and Mitigating Gender Bias in Languages with Grammatical Gender and Bilingual Word Embeddings</a></span> has been accepted by ICML AI for Social Good Workshop.</p>
        <p> * [03.2019] Our paper <span style="color:#4169E1"><a href="https://arxiv.org/abs/1904.03310">Gender Bias in
              Contextualized Word Embeddings </a></span> has been accepted by NAACL 2019.</p>
        <p id="pub"><a href="old_news.html">Not That New News</a></p> -->

    </div>
    <!-- Call to Action Well -->


    <div class=" my-4 text-left">
      <!-- <h2> Preprints</h2>
          <p>(* represents equal contribution)</p>
          <ul>
            <li><b>Adversarial Objects Against LiDAR-Based Autonomous Driving Systems
              </b><p class='content'> Yulong Cao*, Chaowei Xiao*, Dawei Yang*, Jin Fang, Ruigang Yang, Mingyan Liu,  Bo Li. <a href="https://arxiv.org/abs/1907.05418">[pdf]</a></p>
                </li>
          </ul> -->

      <h2>Publications (selected) </h2>
      <p> See <a href="https://scholar.google.com/citations?user=_IogGwwAAAAJ"><i
              class="ai ai-google-scholar-square ai-2x"></i></a> Google scholar </p> 
      <ul>

      <li><b><a href="https://dl.acm.org/doi/10.1145/3664647.3681524">Poisoning for Debiasing: Fair Recognition via Eliminating Bias Uncovered in Data Poisoning</a></b>
          <p class='content'> <strong>Yi Zhang</strong>, Zhefeng Wang, Rui Hu, Xinyu Duan, Yi Zheng, Baoxing Huai, Jiarun Han, and Jitao Sang.
          </p>
          <p>ACM Multimedia Conference. <strong>ACM MM 2024</strong> (CCF-A).</p>
      </li>
        
      <li><b><a href="https://dl.acm.org/doi/10.1145/3581783.3612317">Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features</a></b>
          <p class='content'> <strong>Yi Zhang</strong>, Jitao Sang, Junyang Wang, Dongmei Jiang, and Yaowei Wang.
          </p>
          <p>ACM Multimedia Conference. <strong>ACM MM 2023</strong> (CCF-A).</p>
        </li>

        
      <li><b><a href="https://dl.acm.org/doi/10.1145/3394171.3413772">Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models</a></b>
          <p class='content'> <strong>Yi Zhang</strong>, Junyang Wang, and Jitao Sang.
          </p>
          <p>ACM Multimedia Conference. <strong>ACM MM 2022</strong> (CCF-A).</p>
        </li>
        
        <li><b><a href="https://dl.acm.org/doi/10.1145/3394171.3413772">Towards Accuracy-Fairness Paradox: Adversarial Example-based Data Augmentation for Visual Debiasing</a></b>
          <p class='content'> <strong>Yi Zhang</strong>, Jitao Sang.
          </p>
          <p>ACM Multimedia Conference. <strong>ACM MM 2020</strong> (CCF-A).</p>
        </li>
        <!-- <li><b><a href="https://arxiv.org/abs/1906.08976">Mitigating Gender Bias in Natural Language Processing:
              Literature Review</a></b>
          <p class='content'> Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, <strong>Jieyu
              Zhao</strong>, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, William Yang Wang.</p>
          <p>Association for Computational Linguistics. <strong>ACL 2019</strong>.</p>
        </li>
        <li><b><a href="https://arxiv.org/abs/1904.03310">Gender Bias in Contextualized Word Embeddings</a></b> <a
            href="https://www.youtube.com/watch?v=n9KGNbpnu5c">[video]</a> <a href="files/naacl19.pdf">[slides]</a>
          <p class='content'> <strong>Jieyu Zhao</strong>, Tianlu Wang, Mark Yatskar, Ryan Cotterell, Vicente Ordonez,
            Kai-Wei Chang.</p>
          <p>North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2019</strong>.</p>
        </li>
        <li><b><a href="https://arxiv.org/abs/1809.01496">Learning Gender-Neutral Word Embeddings</a></b> <a
            href="https://github.com/uclanlp/gn_glove">[code]</a>
          <p class='content'> <strong>Jieyu Zhao</strong>, Yichao Zhou, Zeyu Li, Wei Wang, Kai-Wei Chang </p>
          <p> Conference on Empirical Methods in Natural Language Processing. <strong>EMNLP 2018</strong>. </p>
        </li>

        <li><b><a href="https://arxiv.org/abs/1804.06876">Gender Bias in Coreference Resolution: Evaluation and
              Debiasing Methods</a></b> <a href="https://uclanlp.github.io/corefBias/overview">[code]</a> <a
            href="https://soundcloud.com/nlp-highlights/66-gender-bias-in-coreference-resolution-evaluation-and-debiasing-methods-with-jieyu-zhao">[podcast]</a>
          <p class="content"> <strong>Jieyu Zhao</strong>, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang.
          </p>
          <p>North American Chapter of the Association for Computational Linguistics. <strong>NAACL 2018</strong>. </p>
        </li>

        <li><b><a href="https://arxiv.org/abs/1707.09457">Men Also Like Shopping: Reducing Gender Bias Amplification
              using Corpus-level Constraints</a></b> <a href="https://github.com/uclanlp/reducingbias">[code]</a>
          <p class="content"> <strong>Jieyu Zhao</strong>, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang.
          </p>
          <p class="content">Conference on Empirical Methods in Natural Language Processing. <strong>EMNLP
              2017</strong>.
            (<span style="color:rgb(247, 78, 78)">Best Long Paper Award</span>)</p>
          <p class="content">Press: <a
              href="https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/">Wired: Machines
              Taught By Photos Learn a Sexist View of Women</a></p>
        </li> -->
      </ul>
    </div>


 <div class=" my-4 text-left">
      <h2>Talks</h2>
      <ul>
        <li> Tutorial: <span style="color:#4169E1"><a href="https://2021.acmmm.org/tutorials"><b>Trustworthy Multimedia Analysis</b></a></span>, ACM MM 2021 (<b>CCF-A</b>) </li>
      </ul>
    </div>


    
    <div class=" my-4 text-left">
      <h2>Experience/Education</h2>
      <ul>
        <li> Ph.D (computer science), <span style="color:#4169E1"><a href="https://www.bjtu.edu.cn/">Beijing Jiaotong University
        </a></span>. 2019.9 - 2023.6 </li>
        <li> <span style="color:#4169E1"><a href="http://www.pcl.ac.cn/">Peng Cheng Laboratory, China</a></span>. 2020.09 - 2023.05</li>

        <li> M.S (computer science), <span style="color:#4169E1"><a href="https://www.bjtu.edu.cn/">Beijing Jiaotong University
        </a></span>. 2018.9 - 2019.6 </li>
        <li> <span style="color:#4169E1"><a href="http://www.pcl.ac.cn/">Peng Cheng Laboratory, China</a></span>. 2019.06 - 2019.09 </li>

      </ul>
    </div>
<!--     <div class=" my-4 text-left">
      <h2></h2>
      <ul>
      </ul>
    </div> -->
    <!-- <div class=" my-4 text-left">
      <h2>Awards (selected)</h2>
      <ul>
        <li>SoCalNLP Symposium Best Poster Award, 2018</li>
        <li>UCLA Graduate Division Fellowships, 2017</li>
        <li>EMNLP 2017 Best Long Paper Award, 2017</li>
        <li>Outstanding Graduate of Beijing City, 2016</li>
      </ul>
    </div> -->
    <div class=" my-4 text-left">
      <h2>Teaching</h2>
      <ul>
        <li>Teaching Assistant, Machine Learning, Jitao Sang. BJTU, 2020 Fall</li>
        <li>Teaching Assistant, Machine Learning, Jitao Sang &amp; Liping Jing. BJTU, 2019 Fall</li>

        <!-- <li>Teaching Assistant, Algorithm, Kong-Cheng Wong. UVa, 2017 Spring </li>
        <li>Teaching Assistant, Software Development Methods, Nada Basit and David Edwards. UVa, 2017 Spring</li>
        <li>Teaching Assistant, Algorithm, Gabriel Robins. UVa, 2016 Fall </li>
        <li>Teaching Assistant, Discrete Math, David Edwards. UVa, 2016 Fall</li> -->
      </ul>
    </div>
    <!-- Content Row -->
    <!-- /.row -->

  </div>
  <!-- /.container -->

  <!-- Footer -->
  <footer class="py-1 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; Yi Zhang</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
